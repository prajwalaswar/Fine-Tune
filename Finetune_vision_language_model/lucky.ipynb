{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363468c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install bitsandbytes peft trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280c0cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83d7e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_CHECKPOINTING = True,  # Tradeoff between memory efficiency and computation time.\n",
    "USE_REENTRANT = False,\n",
    "OPTIM = \"paged_adamw_32bit\"\n",
    "LEARNING_RATE = 2e-5\n",
    "LOGGING_STEPS = 50\n",
    "EVAL_STEPS = 50\n",
    "SAVE_STEPS = 50\n",
    "EVAL_STRATEGY = \"steps\"\n",
    "SAVE_STRATEGY = \"steps\"\n",
    "METRIC_FOR_BEST_MODEL=\"eval_loss\"\n",
    "LOAD_BEST_MODEL_AT_END=True\n",
    "MAX_GRAD_NORM = 1\n",
    "WARMUP_STEPS = 0\n",
    "DATASET_KWARGS={\"skip_prepare_dataset\": True} # We have to put for VLMs\n",
    "REMOVE_UNUSED_COLUMNS = False # VLM thing\n",
    "MAX_SEQ_LEN=128\n",
    "NUM_STEPS = (283 // BATCH_SIZE) * EPOCHS\n",
    "print(f\"NUM_STEPS: {NUM_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade5b924",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a highly advanced Vision Language Model (VLM), specialized in analyzing, describing, and interpreting visual data.\n",
    "Your task is to process and extract meaningful insights from images, videos, and visual patterns,\n",
    "leveraging multimodal understanding to provide accurate and contextually relevant information.\"\"\"\n",
    "\n",
    "def format_data(sample):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": sample[\"image\"],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": sample[\"query\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": sample[\"label\"][0]}],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a00f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset, test_dataset = load_dataset(\"HuggingFaceM4/ChartQA\",\n",
    "                                                         split=[\"train[:1%]\", \"val[:1%]\", \"test[:1%]\"])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(\"-\"*30)\n",
    "print(train_dataset)\n",
    "print(\"-\"*30)\n",
    "print(train_dataset[0])\n",
    "print(\"-\"*30)\n",
    "\n",
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "eval_dataset = [format_data(sample) for sample in eval_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(\"-\"*30)\n",
    "print(train_dataset[0])\n",
    "print(\"-\"*30)\n",
    "print(len(test_dataset))\n",
    "print(\"-\"*30)\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ff479",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sample_data = test_dataset[0]\n",
    "sample_question = test_dataset[0][1][\"content\"][1][\"text\"]\n",
    "sample_answer = test_dataset[0][2][\"content\"][0][\"text\"]\n",
    "sample_image = test_dataset[0][1][\"content\"][0][\"image\"]\n",
    "\n",
    "print(sample_question)\n",
    "print(sample_answer)\n",
    "sample_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a83e8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        use_cache=False\n",
    "        )\n",
    "\n",
    "else:\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        use_cache=False\n",
    "        )\n",
    "\n",
    "processor = Qwen2VLProcessor.from_pretrained(MODEL_ID)\n",
    "processor.tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6af358",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def text_generator(sample_data):\n",
    "    text = processor.apply_chat_template(\n",
    "        sample_data[0:2], tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    print(f\"Prompt: {text}\")\n",
    "    print(\"-\"*30)\n",
    "\n",
    "    image_inputs = sample_data[1][\"content\"][0][\"image\"]\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images = image_inputs,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=MAX_SEQ_LEN)\n",
    "\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids, skip_special_tokens=True\n",
    "    )\n",
    "    del inputs\n",
    "    actual_answer = sample_data[2][\"content\"][0][\"text\"]\n",
    "    return output_text[0], actual_answer\n",
    "\n",
    "\n",
    "generated_text, actual_answer = text_generator(sample_data)\n",
    "print(f\"Generated Answer: {generated_text}\")\n",
    "print(f\"Actual Answer: {actual_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbac64",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "print(f\"Before adapter parameters: {model.num_parameters()}\")\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters() # After LoRA trainable parameters increases. Since we add adapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbefb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"./output\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    eval_steps=EVAL_STEPS,\n",
    "    eval_strategy=EVAL_STRATEGY,\n",
    "    save_strategy=SAVE_STRATEGY,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    metric_for_best_model=METRIC_FOR_BEST_MODEL,\n",
    "    load_best_model_at_end=LOAD_BEST_MODEL_AT_END,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    dataset_kwargs=DATASET_KWARGS,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    remove_unused_columns = REMOVE_UNUSED_COLUMNS,\n",
    "    optim=OPTIM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afbbee8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "collate_sample = [train_dataset[0], train_dataset[1]] # for batch size 2.\n",
    "\n",
    "def collate_fn(examples):\n",
    "    texts = [processor.apply_chat_template(example, tokenize=False) for example in examples]\n",
    "    image_inputs = [example[1][\"content\"][0][\"image\"] for example in examples]\n",
    "\n",
    "    batch = processor(\n",
    "        text=texts, images=image_inputs, return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
    "    batch[\"labels\"] = batch[\"input_ids\"]\n",
    "\n",
    "    return batch\n",
    "\n",
    "collated_data = collate_fn(collate_sample)\n",
    "print(collated_data.keys())  # dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a0a17",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf8f36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"-\"*30)\n",
    "print(\"Initial Evaluation\")\n",
    "metric = trainer.evaluate()\n",
    "print(metric)\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"Training\")\n",
    "trainer.train()\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeaedfb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e97b79",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "# https://huggingface.co/learn/cookbook/en/fine_tuning_vlm_trl\n",
    "def clear_memory():\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de258b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        use_cache=True\n",
    "        )\n",
    "\n",
    "else:\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        use_cache=True\n",
    "        )\n",
    "\n",
    "processor = Qwen2VLProcessor.from_pretrained(MODEL_ID)\n",
    "processor.tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73164d38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Before adapter parameters: {model.num_parameters()}\")\n",
    "model.load_adapter(\"./output\")\n",
    "print(f\"After adapter parameters: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b552c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "generated_text, actual_answer = text_generator(sample_data)\n",
    "print(f\"Generated Answer: {generated_text}\")\n",
    "print(f\"Actual Answer: {actual_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d16ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
